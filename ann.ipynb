{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gvmcjhCCrNp"
   },
   "source": [
    "### **Importing  libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWlBVRX_C0sL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define utilty functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Utility functions for interacting with the dataset \"\"\"\n",
    "\n",
    "def get_training_image_vector(image_number):\n",
    "    file = open('MNIST Dataset/train-images-idx3-ubyte', 'rb')\n",
    "    file.seek(16 + (image_number - 1) * 784, 0)\n",
    "\n",
    "    image_vector = []\n",
    "    for i in range(0, 784):\n",
    "        byte = int.from_bytes(file.read(1), byteorder='big')\n",
    "        image_vector.append(byte)\n",
    "\n",
    "    file.close()\n",
    "    return image_vector\n",
    "\n",
    "\n",
    "def get_training_image_label(image_number):\n",
    "    file = open('MNIST Dataset/train-labels-idx1-ubyte', 'rb')\n",
    "    file.seek(8 + (image_number - 1), 0)\n",
    "\n",
    "    byte = int.from_bytes(file.read(1), byteorder='big')\n",
    "    image_label = byte\n",
    "\n",
    "    file.close()\n",
    "    return image_label\n",
    "\n",
    "def get_test_image_vector(image_number):\n",
    "    file = open('MNIST Dataset/t10k-images-idx3-ubyte', 'rb')\n",
    "    file.seek(16 + (image_number - 1) * 784, 0)\n",
    "\n",
    "    image_vector = []\n",
    "    for i in range(0, 784):\n",
    "        byte = int.from_bytes(file.read(1), byteorder='big')\n",
    "        image_vector.append(byte)\n",
    "\n",
    "    file.close()\n",
    "    return image_vector\n",
    "\n",
    "\n",
    "def get_test_image_label(image_number):\n",
    "    file = open('MNIST Dataset/t10k-labels-idx1-ubyte', 'rb')\n",
    "    file.seek(8 + (image_number - 1), 0)\n",
    "\n",
    "    byte = int.from_bytes(file.read(1), byteorder='big')\n",
    "    image_label = byte\n",
    "\n",
    "    file.close()\n",
    "    return image_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdMBKv0y-hyh"
   },
   "source": [
    "### **Getting Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "FQlBCYzH-npE",
    "outputId": "6e23b8f6-5bf1-421f-da90-62d0c85d834a"
   },
   "outputs": [],
   "source": [
    "TRAINING_EXAMPLES = 60000\n",
    "INPUT_FEATURES = 784\n",
    "\n",
    "X = np.ones((TRAINING_EXAMPLES, INPUT_FEATURES))\n",
    "y = np.ones(TRAINING_EXAMPLES)\n",
    "\n",
    "for i in range(TRAINING_EXAMPLES):\n",
    "    X[i, 0:] = get_training_image_vector(i + 1)\n",
    "    y[i] = get_training_image_label(i + 1)\n",
    "\n",
    "# Vectorizing output\n",
    "y_vectors = np.zeros((len(y), 10))\n",
    "for i in range(len(y)):\n",
    "    y_vectors[i, int(y[i])] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3gmC0OigRFq"
   },
   "source": [
    "#### **Creating ANN class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIwCXymRgEKp"
   },
   "outputs": [],
   "source": [
    "class ANN:\n",
    "\n",
    "\n",
    "    def __init__(self, X, y, layers=None):\n",
    "        self.X = np.array(X, dtype='float64')\n",
    "        self.y = np.array(y, dtype='float64')\n",
    "        self.features = len(X[0])\n",
    "        self.classes = len(y[0])\n",
    "        self.layers = [self.features, self.classes]\n",
    "        if layers is not None:\n",
    "            self.layers.pop()\n",
    "            self.layers.extend(layers)\n",
    "            self.layers.append(self.classes)\n",
    "\n",
    "        self.m = len(X)\n",
    "        self.layer_count = len(self.layers)\n",
    "\n",
    "\n",
    "    def init_parameters(self, resume):\n",
    "        resumed = False\n",
    "        if resume:\n",
    "            if os.path.exists(\"predictor_bin\"):\n",
    "                outputfile = open('predictor_bin', 'rb')\n",
    "                ann_prev = pickle.load(outputfile)\n",
    "                if ann_prev.layers == self.layers:\n",
    "                    print('Initializing parameters with previously dumped object')\n",
    "                    self.parameters = ann_prev.parameters\n",
    "                    resumed = True\n",
    "        \n",
    "        if not resumed:\n",
    "            print('Fresh initialization of parameters')\n",
    "            self.parameters = []\n",
    "            for i in range(self.layer_count - 1):\n",
    "                np.random.seed(0)\n",
    "                self.parameters.append(np.random.randn(self.layers[i + 1], \n",
    "                            self.layers[i] + 1) * np.sqrt(1 / self.layers[i]))\n",
    "\n",
    "\n",
    "    def init_network(self):\n",
    "        self.neurons = []\n",
    "        for i in range(self.layer_count):\n",
    "            self.neurons.append(np.zeros(self.layers[i]))\n",
    "\n",
    "\n",
    "    def forwardpropagation(self, inp):\n",
    "        self.neurons[0] = inp\n",
    "        for i in range(1, self.layer_count):\n",
    "            layer_prev = np.ones(self.layers[i - 1] + 1)\n",
    "            layer_prev[1:] = self.neurons[i - 1]\n",
    "            self.neurons[i] = np.reciprocal(np.exp((self.parameters[i - 1]\n",
    "                                @ layer_prev) * -1) + 1)\n",
    "\n",
    "\n",
    "    def backpropagation(self):\n",
    "        self.gradients = []\n",
    "        for i in range(self.layer_count - 1):\n",
    "            self.gradients.append(np.zeros((self.layers[i + 1], \n",
    "                                                self.layers[i] + 1)))\n",
    "\n",
    "        for i in range(self.m):\n",
    "            if i % 5000 == 0:\n",
    "                print('\\tBackpropagation: Running for example number {}'.\n",
    "                        format(i))\n",
    "                \n",
    "            self.forwardpropagation(self.X[i, :])\n",
    "            delta = np.zeros((self.classes, 1))\n",
    "            delta[:, 0] = self.neurons[self.layer_count - 1] - self.y[i]\n",
    "            for j in range(self.layer_count - 1, 0, -1):\n",
    "                layer_prev = np.ones((self.layers[j - 1] + 1, 1))\n",
    "                layer_prev[1:, 0] = self.neurons[j - 1]\n",
    "                self.gradients[j - 1] += delta @ layer_prev.transpose()\n",
    "                delta_prev = (((self.parameters[j - 1].transpose() @ delta) * \n",
    "                               (layer_prev * (1 - layer_prev)))[1:, :])\n",
    "                delta = delta_prev\n",
    "    \n",
    "\n",
    "    def cost_function(self):\n",
    "        def cost_per_example(example_number):\n",
    "            self.forwardpropagation(self.X[example_number, :])\n",
    "            output = self.neurons[-1]\n",
    "            cost = 0.0\n",
    "            for j in range(self.classes):\n",
    "                cost1, cost2 = 0, 0\n",
    "                try:\n",
    "                    cost1 = float((-self.y[example_number][j]) * \n",
    "                                  (np.log(output[j]))) / self.m\n",
    "                except ValueError:\n",
    "                    cost1 = -1000.0\n",
    "                try:\n",
    "                    cost2 = (float((1 - self.y[example_number][j]) * \n",
    "                                   (np.log(1 - output[j]))) / self.m) * -1\n",
    "                except ValueError:\n",
    "                    cost2 = -1000.0\n",
    "\n",
    "                cost += cost1 + cost2\n",
    "\n",
    "            return cost\n",
    "\n",
    "        cost = 0.0\n",
    "        for i in range(self.m):\n",
    "            cost += cost_per_example(i)\n",
    "\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def gradient_descent(self, alpha, n_iter):\n",
    "        for i in range(n_iter):\n",
    "            print('Gradient Descent: Running iteration {}'.format(i + 1))\n",
    "            self.backpropagation()\n",
    "            for j in range(self.layer_count - 1):\n",
    "                self.parameters[j] -= (alpha / self.m) * self.gradients[j]\n",
    "            \n",
    "            if i % 30 == 0:\n",
    "                print(\"Gradient Descent: Dumping object after iteration {}\".\n",
    "                      format(i + 1))\n",
    "                outputfile = open('predictor_bin', 'wb')\n",
    "                pickle.dump(self, outputfile)\n",
    "                outputfile.close()\n",
    "\n",
    "\n",
    "    def feature_scaling(self):\n",
    "        self.means = np.mean(self.X, axis=0)\n",
    "        self.scales = np.amax(self.X, axis=0) - np.amin(self.X, axis=0)\n",
    "        for i in range(len(self.scales)):\n",
    "            if self.scales[i] == 0:\n",
    "                self.scales[i] = 1\n",
    "\n",
    "        for i in range(self.m):\n",
    "            self.X[i, :] = self.X[i, :] - self.means\n",
    "            self.X[i, :] = self.X[i, :] / self.scales\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.3, n_iter=500, resume=True):\n",
    "        self.feature_scaling()\n",
    "        self.init_network()\n",
    "        self.init_parameters(resume)\n",
    "        self.gradient_descent(alpha, n_iter)\n",
    "\n",
    "\n",
    "    def predict(self, inp):\n",
    "        x = np.array(inp, dtype='float64')\n",
    "        x -= self.means\n",
    "        x /= self.scales\n",
    "        self.forwardpropagation(x)\n",
    "        return self.neurons[self.layer_count - 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpbnU-TA_PMr"
   },
   "source": [
    "### **Training Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "CkS558Vr_UvZ",
    "outputId": "bd142cd1-8602-4bb7-a283-9b79afb40060"
   },
   "outputs": [],
   "source": [
    "#ann = ANN(X, y_vectors, layers=[80, 80])\n",
    "#ann.fit(alpha=10, resume=True)\n",
    "print('\\nCurrent Cost = {}'.format(ann.cost_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1AaI9f6_bWE"
   },
   "source": [
    "### **Making Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nP_mtc65_Zwu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Accuracy: 96.24%\n"
     ]
    }
   ],
   "source": [
    "TEST_SET_SIZE = 10000\n",
    "\n",
    "X_test = np.ones((TEST_SET_SIZE, INPUT_FEATURES))\n",
    "y_test = np.ones(TEST_SET_SIZE)\n",
    "\n",
    "for i in range(TEST_SET_SIZE):\n",
    "    X_test[i, 0:] = get_test_image_vector(i + 1)\n",
    "    y_test[i] = get_test_image_label(i + 1)\n",
    "\n",
    "outputfile = open('predictor_bin', 'rb')\n",
    "ann = pickle.load(outputfile)\n",
    "\n",
    "predictions, correct_predictions = 0, 0\n",
    "for i in range(len(X_test)):\n",
    "    y_pred = ann.predict(np.array(X_test[i, :], dtype='float64'))\n",
    "    precdiction, prediction_prob = -1, - 1\n",
    "    for j in range(len(y_pred)):\n",
    "        if y_pred[j] > prediction_prob:\n",
    "            prediction_prob = y_pred[j]\n",
    "            prediction = j\n",
    "    if y_test[i] == prediction:\n",
    "        correct_predictions += 1\n",
    "    predictions += 1\n",
    "\n",
    "print('Network Accuracy: {}%'.format((correct_predictions * 100) / predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ann.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
